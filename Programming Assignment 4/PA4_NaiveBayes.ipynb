{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Programming Assignment 4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zbMdNZKHm-7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPoZ4Vlp4CLg"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import collections\n",
        "from collections import Counter\n",
        "from scipy.special import expit\n",
        "import string"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oaEByrYgqlje",
        "outputId": "8ede8ceb-cbae-4341-be85-193ebea53398"
      },
      "source": [
        "!gdown --id 1n0j5zbMXMVnLPUqadFNcCxiZRu0ChoXL\n",
        "!unzip -q \"Programming_Assignment_3.zip\" -d \"\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1n0j5zbMXMVnLPUqadFNcCxiZRu0ChoXL\n",
            "To: /content/Programming_Assignment_3.zip\n",
            "42.0MB [00:00, 74.2MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua7jz0BnMiCR"
      },
      "source": [
        "test = pd.DataFrame()\n",
        "train = pd.DataFrame()\n",
        "label_list = []\n",
        "content = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IIkD2e2AEjHj"
      },
      "source": [
        "def file_reading(datatype,directory):\n",
        "#   files = glob.glob('Dataset/'+datatype+'/'+directory+'/*.txt',  recursive = True)\n",
        "    files = glob.glob('Dataset/'+datatype+'/'+directory+'/*.txt',  recursive = True)\n",
        "\n",
        "    print(\"Files are :\",len(files))\n",
        "  # return\n",
        "    if directory == 'neg':\n",
        "        label = 0\n",
        "    else:\n",
        "        label = 1\n",
        "\n",
        "    print(\"Sentiment is: \",label)\n",
        "    for file in files:\n",
        "        f = open(file,'r')\n",
        "        content.append(f.read())\n",
        "        label_list.append(label)\n",
        "    # print('Content:  ',content[0])\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eksk_PKibMw9",
        "outputId": "1aec689b-4001-45d7-cd24-9810d1aba41d"
      },
      "source": [
        "file_reading('test','neg')\n",
        "file_reading('test','pos')\n",
        "\n",
        "test['Review'] = content\n",
        "test['Label'] = label_list"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files are : 12500\n",
            "Sentiment is:  0\n",
            "Files are : 12500\n",
            "Sentiment is:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9EKNLfapgwjs",
        "outputId": "491bd7fc-6bfe-4cde-8b34-b2e842ca07ff"
      },
      "source": [
        "label_list = []\n",
        "content = []\n",
        "file_reading('train','neg')\n",
        "file_reading('train','pos')\n",
        "train['Review'] = content\n",
        "train['Label'] = label_list"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files are : 12500\n",
            "Sentiment is:  0\n",
            "Files are : 12500\n",
            "Sentiment is:  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mTcWG8ob1fL"
      },
      "source": [
        "def preprocessing(data):\n",
        "  f = open('Dataset/stop_words.txt','r')\n",
        "  stop_words = f.read()\n",
        "  punctuation = string.punctuation\n",
        "\n",
        "  data['Review'] = data['Review'].str.replace('<br />',' ')\n",
        "  data['Review'] = data['Review'].str.replace('[^\\w\\s*-]',' ')\n",
        "  data['Review'] = data['Review'].str.replace('[\\d]',' ')\n",
        "  data['Review'] = data['Review'].str.lower()\n",
        "  data['without_stopwords'] = data['Review'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
        "  data['Review'] = data['without_stopwords']\n",
        "  data.drop(columns='without_stopwords',inplace = True)\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXh0wc02IIoT"
      },
      "source": [
        "train = preprocessing(train)\n",
        "test = preprocessing(test)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "Bs5sc_zxIfzu",
        "outputId": "17e83284-c9b0-4ebe-9bfc-3b2c21669f08"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>superdome one movies makes wonder made whole p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>saw remember advertisements movie interested f...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>okay say revealing monster saying really fit c...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>possible spoiler think story involving archie ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>like movie genre good gangster movies bad gang...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Label\n",
              "0  superdome one movies makes wonder made whole p...      0\n",
              "1  saw remember advertisements movie interested f...      0\n",
              "2  okay say revealing monster saying really fit c...      0\n",
              "3  possible spoiler think story involving archie ...      0\n",
              "4  like movie genre good gangster movies bad gang...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjA3vIlnJASm"
      },
      "source": [
        "# Part 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVqYupHmLHW8",
        "outputId": "35658653-073f-4b06-df87-cee6b574fbc9"
      },
      "source": [
        "type(train['Label'][0])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eq5LaCcfMkKD"
      },
      "source": [
        "def unique_words(D):\n",
        "  unique_list = set()\n",
        "  list_words = D.str.split()\n",
        "  list_words.apply(unique_list.update)\n",
        "  unique_list = list(unique_list)\n",
        "\n",
        "  return unique_list, len(unique_list)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8rdZQZsQVFt"
      },
      "source": [
        "def vocab(D):\n",
        "  count = 0\n",
        "  total_vocab = []\n",
        "  list_words = D.str.split()\n",
        "  for i in list_words:\n",
        "    count = count + len(i)\n",
        "    for w in i:\n",
        "      total_vocab.append(w)\n",
        "  # print(list_words)\n",
        "  return count,total_vocab"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtIZa2ATQd49",
        "outputId": "21b50535-1a03-4632-e53f-20d8f759b93b"
      },
      "source": [
        "# cnt, list_v = vocab(train['Review'])\n",
        "# list_v[:5]\n",
        "len(train[train['Label']==0]['Review'])\n",
        "uniq_ls,cnt = (unique_words(train['Review']))\n",
        "len(uniq_ls)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "93647"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hyynMUiO9ee"
      },
      "source": [
        "# unique_words(train['Review'])\n",
        "# cnt"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkUKtkZNN6eu"
      },
      "source": [
        "# unique_list = set()\n",
        "# list_words = train['Review'].str.split()\n",
        "# list_words.apply(unique_list.update)\n",
        "# unique_list = list(unique_list)\n",
        "# len(unique_list)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w1U-cMu0yEmY"
      },
      "source": [
        "def alt_denomenator(V,list_of_words):\n",
        "  print('Calculating denomenator for likelihood! (using alt method)')\n",
        "  total = len(list_of_words)\n",
        "  unique_words = len(V)\n",
        "\n",
        "  count = total+unique_words\n",
        "  return count"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xm3qYwMXgBB"
      },
      "source": [
        "def denominator(V,list_of_words):\n",
        "  print('Calculating denomenator for likelihood!')\n",
        "  print(list_of_words[0:5])\n",
        "  print('number of words in V: ',len(V))\n",
        "  count = 0\n",
        "  for word in V:\n",
        "    word_cnt = list_of_words.count(word)\n",
        "    count = count + (word_cnt + 1)\n",
        "  return count"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-58B6C5WIjrN"
      },
      "source": [
        "def train_NB(D,C):\n",
        "  print(D['Review'].head())\n",
        "  count = {}\n",
        "  loglikelihood = {}\n",
        "  logprior = np.zeros(len(C))\n",
        "  bigdoc = {}\n",
        "  for class_i in C:\n",
        "    print(\"Running for class \",class_i)\n",
        "    N_doc = len(D['Review'])\n",
        "    N_class = len(D[D['Label']==class_i]['Review'])\n",
        "    logprior[int(class_i)] = np.log(N_class / N_doc)\n",
        "    V , cntV= unique_words(D['Review'])\n",
        "    _, bigdoc[int(class_i)] = vocab(D[D['Label']==class_i]['Review'])\n",
        "    # sampled_denom = denominator(V,bigdoc[class_i])\n",
        "    sampled_denom2 = alt_denomenator(V,bigdoc[class_i])\n",
        "    # print('Value of denom ',sampled_denom)\n",
        "    print('Value of denom 2 ',sampled_denom2)\n",
        "    # return 0\n",
        "    print('Calculating Log liklihood Next')\n",
        "    word_cnt = Counter(bigdoc[class_i])\n",
        "    for word in V:\n",
        "      if word in word_cnt.keys():\n",
        "        count[(word,class_i)] = word_cnt[word]\n",
        "      else:\n",
        "        count[(word,class_i)] = 0\n",
        "      # sampled_denom = alt_denomenator(V,bigdoc[class_i])\n",
        "      # print('Value of denom ',sampled_denom)\n",
        "      # count[(word,class_i)] = bigdoc[class_i].count(word)\n",
        "      # if count == 0:\n",
        "      #   print(word)\n",
        "      loglikelihood[(word,class_i)] = np.log((count[(word,class_i)] + 1) / sampled_denom2)\n",
        "      # print(loglikelihood)\n",
        "  \n",
        "  return logprior,loglikelihood,V\n",
        "\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lf3fqI0sYZ0O",
        "outputId": "68a4ac44-dc47-426d-9973-22898d3203e4"
      },
      "source": [
        "C = list(set(train['Label']))\n",
        "C"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YtQqaNB9SB_M"
      },
      "source": [
        "# train_NB(train,C)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i38srsk8YTHV",
        "outputId": "36f7dc72-69f6-4f8f-f146-c356b89d82e7"
      },
      "source": [
        "logprior,loglikelihood,V = train_NB(train,C)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    superdome one movies makes wonder made whole p...\n",
            "1    saw remember advertisements movie interested f...\n",
            "2    okay say revealing monster saying really fit c...\n",
            "3    possible spoiler think story involving archie ...\n",
            "4    like movie genre good gangster movies bad gang...\n",
            "Name: Review, dtype: object\n",
            "Running for class  0\n",
            "Calculating denomenator for likelihood! (using alt method)\n",
            "Value of denom 2  1520311\n",
            "Calculating Log liklihood Next\n",
            "Running for class  1\n",
            "Calculating denomenator for likelihood! (using alt method)\n",
            "Value of denom 2  1586003\n",
            "Calculating Log liklihood Next\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd4JHxxaXhCh"
      },
      "source": [
        "# loglikelihood[('resignation',0)]"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWqlBk7iX8PM"
      },
      "source": [
        "# np.log(0.5)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbQBRR6VYn-d"
      },
      "source": [
        "def test_NB(testdoc,logprior,loglikelihood,C,V):\n",
        "  sum = np.zeros(len(C))\n",
        "  set_V = set(V)\n",
        "  # print(len(V),len(set_V))\n",
        "  # return 0\n",
        "  for class_i in C:\n",
        "    sum[class_i] = logprior[class_i]\n",
        "    for i in testdoc.split():\n",
        "      word = i\n",
        "      # print(word)\n",
        "      # return 0\n",
        "      if word in set_V:\n",
        "        sum[class_i] = sum[class_i]+ loglikelihood[(word,class_i)]\n",
        "  return np.argmax(sum)\n"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEmB2r0cY3uJ"
      },
      "source": [
        "# lbl = test_NB(test['Review'][i],logprior,loglikelihood,C,V)\n",
        "# lbl"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d-WJwQhnZL47"
      },
      "source": [
        "predicted_lbls = []\n",
        "for i in range(len(test['Review'])):\n",
        "  lbl = test_NB(test['Review'][i],logprior,loglikelihood,C,V)\n",
        "  predicted_lbls.append(lbl)\n",
        "  # if i % 1000 ==0:\n",
        "  #   print('Running ', i)  \n",
        "  # if i == 100:\n",
        "  #   # print('Running')\n",
        "  #   break\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "CpPoK_5jdkn8",
        "outputId": "160f35bf-2f86-496c-8cae-e5f6074353db"
      },
      "source": [
        "test['Predicted'] = predicted_lbls\n",
        "test.head()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Label</th>\n",
              "      <th>Predicted</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>word honor erased vocabularies nations aggrava...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>starts fairly well quite disturbing quickly si...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pretentious - varying degrees - watchable coll...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>american movie industry tries critically look ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>much love film fan bad films love film bad goo...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Label  Predicted\n",
              "0  word honor erased vocabularies nations aggrava...      0          0\n",
              "1  starts fairly well quite disturbing quickly si...      0          0\n",
              "2  pretentious - varying degrees - watchable coll...      0          0\n",
              "3  american movie industry tries critically look ...      0          0\n",
              "4  much love film fan bad films love film bad goo...      0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tH-ftiNjhPWd"
      },
      "source": [
        "def classification_accuracy(actual, predicted):\n",
        "    total = len(actual)\n",
        "    correct = 0\n",
        "    for i in range(total):\n",
        "        if actual[i] == predicted[i]:\n",
        "            correct = correct + 1\n",
        "  # query = np.where(actual == predicted,1,0)\n",
        "  # occurrence_counts = Counter(query)\n",
        "  # correct = occurrence_counts[1]\n",
        "    accuracy = (correct/total) * 100\n",
        "\n",
        "    return accuracy"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RqU5fWfTYWb6",
        "outputId": "339900b8-1a17-409f-fd38-93615d624605"
      },
      "source": [
        "print('Accuracy of the model is: ',classification_accuracy(test['Label'],test['Predicted']),'%')\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the model is:  82.852 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2b502IMGjGLb"
      },
      "source": [
        "# Part 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_b6tJ5TjD8_"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sSWjab_u1QQN"
      },
      "source": [
        "vectorizer = CountVectorizer()\n",
        "train_X = vectorizer.fit_transform(train['Review'])\n",
        "train_y = train['Label']\n",
        "\n",
        "test_X = vectorizer.transform(test['Review'])\n",
        "test_y = train['Label']"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFiGiT0I3Onz",
        "outputId": "a1d42655-8a15-49c4-dcad-9e75d7938017"
      },
      "source": [
        "clf = MultinomialNB()\n",
        "clf.fit(train_X, train_y)\n",
        "\n",
        "y_predicted = clf.predict(test_X)\n",
        "print(\"The accuracy is : \",accuracy_score(test_y, y_predicted))\n",
        "print('Confusion Matrix:\\n',confusion_matrix(test_y, y_predicted))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracy is :  0.82564\n",
            "Confusion Matrix:\n",
            " [[11015  1485]\n",
            " [ 2874  9626]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdGL6b5Ygb1Q"
      },
      "source": [
        ""
      ],
      "execution_count": 32,
      "outputs": []
    }
  ]
}